<p></p>

<p>
<ul>

<h2>NEWS</h2>

<p>
  <ul>
      <li> A <a href=https://github.com/tobipaxe/MaxSAT-Fuzzer>MaxSAT fuzzing toolsuite</a> for comprehensive testing of MAxSAT solvers is now available on <a href=https://github.com/tobipaxe/MaxSAT-Fuzzer>Github</a>.</li>
      <li>The regression suite that solvers participating in the main tracks need to pass is available on <a href="https://github.com/tobipaxe/MaxSATRegressionSuite/tree/main">Github</a></li>
      <li>The deadline for submitting solvers and benchmarks: <b>June 10.</b> </li>
      <li><a href="rules.html"><b>New rules for this year.</b></a> 1. Closed source external libraries are not allowed. 2. Correct exit codes of solvers required. 
          3. Solvers in main tracks need to pass a regression suite.</li>
      <li><a href="guidelines.html"><b>New guidelines on solver robustness and testing.</b></a></li>
      <li><a href="http://www.pragmaticsofsat.org/2024/"><b>Pragmatics of SAT 2024</b></a> 'Competition track'. PoS 2024 invites submissions describing tools being submitted to any competition associated with the main SAT conference. </li>
      <li>Webpage is up.</li>
  </ul>
</p>

<h2>About MSE 2024</h2>

  <p>
    The 2024 MaxSAT Evaluation (<b>MSE 2024</b>) is the 19th edition
    of MaxSAT evaluations, the primary competition-style event
    focusing on the evaluation of MaxSAT
    solvers organized yearly since
    2006.
    </p>

  <p>
    The main goals of MaxSAT Evaluation 2024  are
    <ol>
      <li> to assess the state of the art in the field of MaxSAT
        solvers,
      <li> to collect and re-distribute a heterogeneous MaxSAT
        benchmark set for further scientific evaluations, and
      <li> to promote MaxSAT as a viable option for solving
        instances of a wide range of NP-hard optimization problems.
      </ol>
    </p>
  
  <p>
    <b>MSE 2024 welcomes contributions</b> of two types from the community at large:
    <ol>
      <li> New <b>MaxSAT benchmarks</b> encoding instances of
        interesting NP-hard optimization problems, and
      <li> implementations of <b>MaxSAT solvers</b> that will be
        evaluated within MSE 2024 on a heterogeneous collection of
        benchmarks.
    </ol>
 </p>


  <p><b>MSE 2024</b> is run
     as a collaboration
    between Carnegie Mellon University (USA), University of Freiburg (Germany), and University of Helsinki (Finland).</p>


	</tr></table>
      </p>
